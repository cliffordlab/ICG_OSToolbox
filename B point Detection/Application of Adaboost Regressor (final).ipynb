{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Adaboost Regressor to find B point\n",
    "\n",
    "For details refer to\n",
    "\n",
    "Shafa-at Ali Sheikh, Nil Z. Gurel, Shishir Gupta, Ikenna V. Chukwu, Oleksiy Levantsevych, Mhmtjamil Alkhalaf, Majd Soudan, Rami Abdulbaki, Ammer Haffar, Omer T. Inan, Amit J. Shah, Gari D. Clifford, Ali Bahrami Rad. \"Data-Driven Approach for Automatic Detection of Aortic Valve Opening: B-point Detection from Impedance Cardiogram”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subj_id</th>\n",
       "      <th>feat_vec_out_  1</th>\n",
       "      <th>feat_vec_out_  2</th>\n",
       "      <th>feat_vec_out_  3</th>\n",
       "      <th>feat_vec_out_  4</th>\n",
       "      <th>feat_vec_out_  5</th>\n",
       "      <th>feat_vec_out_  6</th>\n",
       "      <th>feat_vec_out_  7</th>\n",
       "      <th>feat_vec_out_  8</th>\n",
       "      <th>...</th>\n",
       "      <th>mag_C_max_2D</th>\n",
       "      <th>Diff_notch_infl</th>\n",
       "      <th>Diff_RC_notch</th>\n",
       "      <th>Diff_RC_infl</th>\n",
       "      <th>Diff_RC_max_2D</th>\n",
       "      <th>RC</th>\n",
       "      <th>RB_infl</th>\n",
       "      <th>RB_notch</th>\n",
       "      <th>RB_max_2D</th>\n",
       "      <th>RB_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D_102D3_B_1</td>\n",
       "      <td>D_102</td>\n",
       "      <td>-0.204879</td>\n",
       "      <td>-0.191116</td>\n",
       "      <td>-0.177550</td>\n",
       "      <td>-0.164218</td>\n",
       "      <td>-0.151132</td>\n",
       "      <td>-0.138285</td>\n",
       "      <td>-0.125667</td>\n",
       "      <td>-0.113264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415008</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D_102D3_B_2</td>\n",
       "      <td>D_102</td>\n",
       "      <td>0.014109</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.036156</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>0.058157</td>\n",
       "      <td>0.069116</td>\n",
       "      <td>0.080022</td>\n",
       "      <td>0.090851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501384</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D_102D3_B_3</td>\n",
       "      <td>D_102</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>0.034661</td>\n",
       "      <td>0.047875</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414927</td>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "      <td>97</td>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D_102D3_B_4</td>\n",
       "      <td>D_102</td>\n",
       "      <td>-0.323237</td>\n",
       "      <td>-0.310921</td>\n",
       "      <td>-0.298491</td>\n",
       "      <td>-0.285942</td>\n",
       "      <td>-0.273269</td>\n",
       "      <td>-0.260470</td>\n",
       "      <td>-0.247544</td>\n",
       "      <td>-0.234484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>101</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D_102D3_B_5</td>\n",
       "      <td>D_102</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.042397</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>0.064796</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>0.087703</td>\n",
       "      <td>0.099117</td>\n",
       "      <td>0.110398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406913</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id subj_id  feat_vec_out_  1  feat_vec_out_  2  feat_vec_out_  3  \\\n",
       "0  D_102D3_B_1   D_102         -0.204879         -0.191116         -0.177550   \n",
       "1  D_102D3_B_2   D_102          0.014109          0.025135          0.036156   \n",
       "2  D_102D3_B_3   D_102         -0.016475         -0.004135          0.008555   \n",
       "3  D_102D3_B_4   D_102         -0.323237         -0.310921         -0.298491   \n",
       "4  D_102D3_B_5   D_102          0.031615          0.042397          0.053486   \n",
       "\n",
       "   feat_vec_out_  4  feat_vec_out_  5  feat_vec_out_  6  feat_vec_out_  7  \\\n",
       "0         -0.164218         -0.151132         -0.138285         -0.125667   \n",
       "1          0.047166          0.058157          0.069116          0.080022   \n",
       "2          0.021519          0.034661          0.047875          0.061056   \n",
       "3         -0.285942         -0.273269         -0.260470         -0.247544   \n",
       "4          0.064796          0.076233          0.087703          0.099117   \n",
       "\n",
       "   feat_vec_out_  8  ...  mag_C_max_2D  Diff_notch_infl  Diff_RC_notch  \\\n",
       "0         -0.113264  ...      0.415008               37             56   \n",
       "1          0.090851  ...      0.501384               57             41   \n",
       "2          0.074121  ...      0.414927               57             40   \n",
       "3         -0.234484  ...      0.628691                0              0   \n",
       "4          0.110398  ...      0.406913               66             34   \n",
       "\n",
       "   Diff_RC_infl  Diff_RC_max_2D   RC  RB_infl  RB_notch  RB_max_2D  RB_out  \n",
       "0            93              23   93        0        37         70      37  \n",
       "1            98              34   98        0        57         64      57  \n",
       "2            97              29   97        0        57         68      57  \n",
       "3            64              33  101       37         0         68      37  \n",
       "4           100              31  100        0        66         69      66  \n",
       "\n",
       "[5 rows x 468 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset  = pd.read_csv('features_final_465.csv')    # raw dataset\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting subject IDs for subject-wise training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading unique Subject Ids\n",
    "X_ID = dataset.iloc[:, 1].values\n",
    "(unique_ids, counts) = np.unique(X_ID, return_counts=True)\n",
    "\n",
    "outer_train_lists =[]\n",
    "outer_test_lists = []   # outer test list  will be used for testing the final \n",
    "\n",
    "outer_folds = 10\n",
    "\n",
    "kfold_outer = KFold(n_splits=outer_folds, random_state=0, shuffle=True)\n",
    "for outer_train_ix, outer_test_ix in kfold_outer.split(unique_ids):\n",
    "    outer_train_lists.append(unique_ids[outer_train_ix].tolist())    # train folds from outer cv in form of list\n",
    "    outer_test_lists.append(unique_ids[outer_test_ix].tolist())      # test fold from outer cv in form of list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for 10 folds found via 5-fold nested CV (for details refer to the publication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters for 10 folds found via 5-fold nested CV (for details refer to Publication)\n",
    "max_feat = [0.7,0.3,0.7,0.7,0.7,0.7,0.7,0.7,0.7,0.7]\n",
    "max_dep  = [12,10,20,15,15,20,15,12,22,15]\n",
    "LR       = [0.1,0.05,1,0.1,0.5,1,1,1,0.1,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Adaboost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer fold: 0\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=12,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 2.82157018842347\n",
      "\n",
      "Outer fold: 1\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10,\n",
      "                                                       max_features=0.3,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.05, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 6.283996662785276\n",
      "\n",
      "Outer fold: 2\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=20,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 1.991304347826087\n",
      "\n",
      "Outer fold: 3\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 2.523548987388989\n",
      "\n",
      "Outer fold: 4\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.5, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 2.2332355863021336\n",
      "\n",
      "Outer fold: 5\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=20,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 5.351282051282051\n",
      "\n",
      "Outer fold: 6\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 2.978949655444789\n",
      "\n",
      "Outer fold: 7\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=12,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 4.495318068479064\n",
      "\n",
      "Outer fold: 8\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=22,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.1, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 2.2642045454545454\n",
      "\n",
      "Outer fold: 9\n",
      "Best Inner Model AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=15,\n",
      "                                                       max_features=0.7,\n",
      "                                                       random_state=10),\n",
      "                  learning_rate=0.01, loss='exponential', n_estimators=500,\n",
      "                  random_state=1)\n",
      "Mean Absolute Error: 3.663798423475964\n",
      "\n",
      "Results for predicted RB\n",
      "\tOuter fold MAE  [2.82157018842347, 6.283996662785276, 1.991304347826087, 2.523548987388989, 2.2332355863021336, 5.351282051282051, 2.978949655444789, 4.495318068479064, 2.2642045454545454, 3.663798423475964]\n",
      "\tOuter fold median absolute error [0.0833333333333286, 0.7142857142857082, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "Overall MAE for pred:  3.5319423741091738\n",
      "\n",
      "Overall Median Abs Error for pred:  0.0\n",
      "\n",
      "Overall SDE: 9.207337258458578\n",
      "\tPearsons correlation: 0.904\n"
     ]
    }
   ],
   "source": [
    "outer_fold_MAE   = []\n",
    "outer_fold_SDE   = []\n",
    "outer_fold_MedAE = []\n",
    "fold_df_list     = []\n",
    "\n",
    "for out_fold in range(outer_folds):  \n",
    "    print('\\nOuter fold:', out_fold)\n",
    "    outer_train_ids      = outer_train_lists[out_fold]      # list of subj_ids for out_fold   \n",
    "# dataframe of train beats for outer train fold\n",
    "    outer_train_beats_df = dataset[dataset.subj_id.str.contains('|'.join(outer_train_ids ))]   \n",
    "    X_tr_out             = outer_train_beats_df.iloc[:,2 :-1].values\n",
    "    y_tr_out             = outer_train_beats_df.iloc[:, -1].values        # seleccting the last column \n",
    "    #outer_train          = np.array(outer_train_lists[out_fold])         # subj IDs for training\n",
    "\n",
    "# Adaboost Regressor     \n",
    "    best_base_est    = DecisionTreeRegressor(max_features= max_feat[out_fold], \n",
    "                                             max_depth=max_dep[out_fold],\n",
    "                                             random_state=10)\n",
    "\n",
    "    Best_inner_model =  AdaBoostRegressor(base_estimator= best_base_est,\n",
    "                                          loss='exponential', n_estimators=500,\n",
    "                                          learning_rate= LR[out_fold],                                           \n",
    "                                          random_state=1) \n",
    "    print('Best Inner Model',Best_inner_model)\n",
    "    \n",
    "# Extracting test dataset for outer CV\n",
    "    search_values         = outer_test_lists[out_fold]\n",
    "    outer_test_beats_df   = dataset[dataset.subj_id.str.contains('|'.join(search_values ))]\n",
    "\n",
    "# Extracting beats with features\n",
    "    outer_test_fless_df   = outer_test_beats_df.loc[(outer_test_beats_df['RB_notch'] < 35) & (outer_test_beats_df['RB_infl'] < 35)] \n",
    "    y_pred_fless          = outer_test_fless_df.iloc[:,-2].values   # RB_max_2D\n",
    "    y_test_fless          = outer_test_fless_df.iloc[:,-1].values   # RB_out\n",
    "    fless_test_rows_index = outer_test_fless_df.index\n",
    "    outer_test_feat_df    = outer_test_beats_df.drop(fless_test_rows_index) \n",
    "    \n",
    "# Test ids for beats and subjects with and with out features    \n",
    "    id_beat_test       = outer_test_beats_df.iloc[:,0].values\n",
    "    id_beat_test_feat  = outer_test_feat_df.iloc[:,0].values\n",
    "    id_beat_test_fless = outer_test_fless_df.iloc[:,0].values\n",
    "    id_beat_test_all   = np.concatenate((id_beat_test_feat, id_beat_test_fless))\n",
    "    id_subj_feat       = outer_test_feat_df.iloc[:,1].values\n",
    "    id_subj_fless      = outer_test_fless_df.iloc[:,1].values\n",
    "    id_subj_all        = np.concatenate((id_subj_feat, id_subj_fless))\n",
    "\n",
    "    X_test_feat  = outer_test_feat_df.iloc[:,2 :-1].values\n",
    "    y_test_feat  = outer_test_feat_df.iloc[:,-1].values\n",
    "    scaler_out   = StandardScaler()\n",
    "    X_tr_out     = scaler_out.fit_transform(X_tr_out)\n",
    "    X_test_feat  = scaler_out.transform(X_test_feat)\n",
    "    \n",
    "#   Applying best inner model       \n",
    "    result_outer = Best_inner_model.fit(X_tr_out,y_tr_out)       # trained on all data\n",
    "    y_pred_feat  = result_outer.predict(X_test_feat)\n",
    "    y_test_all   = np.concatenate((y_test_feat, y_test_fless))   \n",
    "    y_pred_all   = np.concatenate((y_pred_feat, y_pred_fless))\n",
    "\n",
    "#   Computing Performance Statistics\n",
    "    MAE_fold     = mean_absolute_error(y_test_all, y_pred_all)\n",
    "    MedAE_fold   = median_absolute_error(y_test_all, y_pred_all)\n",
    "    outer_fold_MAE.append(MAE_fold)\n",
    "    outer_fold_MedAE.append(MedAE_fold)\n",
    "    outer_fold_SDE.append(np.std(np.absolute(y_test_all - y_pred_all)))\n",
    "    print('Mean Absolute Error:', MAE_fold)\n",
    "\n",
    "# Saving results for further detailed analysis\n",
    "    RB_max_2D_feat    = outer_test_feat_df.iloc[:,-2].values\n",
    "    RB_notch_feat     = outer_test_feat_df.iloc[:,-3].values\n",
    "    RB_infl_feat      = outer_test_feat_df.iloc[:,-4].values\n",
    "    RC_feat           = outer_test_feat_df.iloc[:,-5].values\n",
    "    RB_max_2D_fless   = outer_test_fless_df.iloc[:,-2].values\n",
    "    RB_notch_fless    = outer_test_fless_df.iloc[:,-3].values\n",
    "    RB_infl_fless     = outer_test_fless_df.iloc[:,-4].values\n",
    "    RC_fless          = outer_test_fless_df.iloc[:,-5].values\n",
    "    RB_max_2D_all     = np.concatenate((RB_max_2D_feat, RB_max_2D_fless))\n",
    "    RB_notch_all      = np.concatenate((RB_notch_feat, RB_notch_fless))\n",
    "    RB_infl_all       = np.concatenate((RB_infl_feat, RB_infl_fless))\n",
    "    RC_all            = np.concatenate((RC_feat, RC_fless))\n",
    "    RB_poly_all       = 1.233*RC_all - 0.0032*(RC_all**2) -31.59    # Lozano RB quadratic\n",
    "    Diff_RB_test_pred = y_test_all - y_pred_all\n",
    "\n",
    "    y_result = np.concatenate((\n",
    "                        out_fold*np.ones(len(y_test_all)).reshape(len(y_test_all),1),\n",
    "                        id_beat_test_all.reshape(len(y_test_all),1), \n",
    "                        id_subj_all.reshape(len(y_test_all),1), \n",
    "                        RC_all.reshape(len(y_test_all),1),     \n",
    "                        RB_poly_all.reshape(len(y_test_all),1),     \n",
    "                        RB_notch_all.reshape(len(y_test_all),1), \n",
    "                        RB_infl_all.reshape(len(y_test_all),1), \n",
    "                        RB_max_2D_all.reshape(len(y_test_all),1), \n",
    "                        y_test_all.reshape(len(y_test_all),1),\n",
    "                        y_pred_all.reshape(len(y_pred_all),1), \n",
    "                        Diff_RB_test_pred.reshape(len(y_pred_all),1),         \n",
    "                                  ),1) \n",
    "    y_df = pd.DataFrame(y_result)\n",
    "    fold_df_list.append(y_df)\n",
    "\n",
    "\n",
    "print('\\nResults for predicted RB')    \n",
    "print('\\tOuter fold MAE ', outer_fold_MAE)\n",
    "print('\\tOuter fold median absolute error', outer_fold_MedAE)\n",
    "\n",
    "final_data_df = pd.concat(fold_df_list)\n",
    "#pd.DataFrame(final_data_df).to_csv(\"Result_AB.csv\")    # detailed result for further analysis\n",
    "\n",
    "RB_test       = final_data_df.iloc[:,8]\n",
    "RB_pred       = final_data_df.iloc[:,9]\n",
    "corr_AB, _    = pearsonr(RB_test, RB_pred)\n",
    "\n",
    "print('\\nOverall MAE for pred: ', mean_absolute_error(RB_test, RB_pred))\n",
    "print('\\nOverall Median Abs Error for pred: ', median_absolute_error(RB_test, RB_pred))\n",
    "print('\\nOverall SDE:', np.std(RB_test - RB_pred))\n",
    "print('\\tPearsons correlation: %.3f' % corr_AB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
